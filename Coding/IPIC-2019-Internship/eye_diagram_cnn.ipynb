{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import packages + libraries for later use\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import specific modules needed for CNN\n",
    "\n",
    "from VisualiseFilters import SaliencyMask, GradientSaliency, VisualBackprop, deprocess_image, vis_img_in_filter, get_layer_names, activation_maps\n",
    "from Predictions import make_predictions, show_predictions\n",
    "from ViewHistory import view_history\n",
    "from GetImages import get_images\n",
    "from Shuffling import stratified_shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset which will be learned\n",
    "data = 'disp'\n",
    "GRAY=True\n",
    "## Desired resolution of images e.g. (28x28)\n",
    "img_res = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File directory to jpg folder\n",
    "train_dir = 'C:/Users/barry.odonnell/Python/input_eye/train_jpg_files_{}'.format(data)\n",
    "\n",
    "## Collects training images and test images\n",
    "train_imgs = ['C:/Users/barry.odonnell/Python/input_eye/train_jpg_files_{}/{}'.format(data, i) for i in os.listdir(train_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data == 'disp':\n",
    "    data = 'disp-short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain image and label arrays\n",
    "X,y = get_images(train_imgs, img_res, GRAY=GRAY, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images is: (1547, 227, 227, 1)\n",
      "Shape of labels is:       (1547, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create an array of each value in the set and assign them integers from 0-36 \n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"Shape of train images is:\", X.shape) ## Check for correct shape, should have 4 axes\n",
    "print(\"Shape of labels is:       ({}, {})\".format(len(Y), max(Y) + 1))\n",
    "\n",
    "y = np.array(y)\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified shuffling...\n",
      "Finish stratified shuffling...\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = stratified_shuffling(X, Y, val_percent=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model...\n",
      "\n",
      "Model ('eye_keras_cnn-model_disp-short_227.h5') built...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 217, 217, 8)       976       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 217, 217, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 54, 54, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 46, 46, 64)        41536     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 38, 38, 16)        82960     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 38, 38, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 16)          20752     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 51529)             875993    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 51529)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 51529)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                515300    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,537,517\n",
      "Trainable params: 1,537,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Begin definition for Neural Network model.\n",
    "##  A Convolutional Neural Network (CNN) is used for its\n",
    "##  versatility with images, and it's feature map ability.\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## Insert image dimensions, preferably square, includinig channel\n",
    "## Number of classes\n",
    "img_dim = (img_res,img_res,1)\n",
    "n_classes = max(Y) + 1\n",
    "\n",
    "model_name = 'eye_keras_cnn-model_{}_{}.h5'.format(data, img_res)\n",
    "#model_name = 'model.h5'\n",
    "## Checks if this model exists.\n",
    "##  If it does, loads said model and skips model building.\n",
    "if os.path.exists(model_name):\n",
    "    print(\"Loading model...\")\n",
    "    model = load_model(model_name)\n",
    "    print(\"{} has been loaded...\".format(model_name))\n",
    "    \n",
    "## Else, builds 'Sequential' model and will contain the layers stated below \n",
    "##  https://keras.io/layers/core/\n",
    "##  https://keras.io/layers/convolutional/\n",
    "else:\n",
    "    print(\"Building Model...\")\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(8, (11,11), input_shape=(img_dim), kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (4,4)))\n",
    "\n",
    "    model.add(Conv2D(64, (9,9), input_shape=(img_dim), kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(16, (9,9), input_shape=(img_dim), kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (3,3)))\n",
    "    \n",
    "    model.add(Conv2D(16, (9,9), input_shape=(img_dim), kernel_initializer='normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (3,3)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(img_res**2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy']\n",
    "                 )\n",
    "    \n",
    "    print(\"\\nModel ('{}') built...\".format(model_name))\n",
    "\n",
    "## Returns model info for user to review and check that it is correct\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    samplewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    samplewise_std_normalization = False,\n",
    "    zca_whitening = False,\n",
    "    rotation_range = 0,\n",
    "    zoom_range = 0,\n",
    "    width_shift_range = .3,\n",
    "    height_shift_range = 0,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = False\n",
    "    )\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/25\n",
      "10/10 [==============================] - 162s 16s/step - loss: 2.2916 - acc: 0.1094 - val_loss: 2.2297 - val_acc: 0.1419\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 145s 15s/step - loss: 2.1383 - acc: 0.1469 - val_loss: 2.0927 - val_acc: 0.2108\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 160s 16s/step - loss: 1.8736 - acc: 0.2687 - val_loss: 1.9283 - val_acc: 0.2301\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 140s 14s/step - loss: 1.6728 - acc: 0.3283 - val_loss: 1.4938 - val_acc: 0.4473\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 140s 14s/step - loss: 1.4206 - acc: 0.3906 - val_loss: 1.2919 - val_acc: 0.4753\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 138s 14s/step - loss: 1.1757 - acc: 0.5344 - val_loss: 1.1000 - val_acc: 0.5914\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 140s 14s/step - loss: 1.0470 - acc: 0.6059 - val_loss: 0.9220 - val_acc: 0.5763\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 145s 15s/step - loss: 0.8939 - acc: 0.5969 - val_loss: 0.8633 - val_acc: 0.6043\n",
      "Epoch 9/25\n",
      " 3/10 [========>.....................] - ETA: 1:03 - loss: 0.8032 - acc: 0.6875"
     ]
    }
   ],
   "source": [
    "# Begin testing on model\n",
    "print('Training model...')\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size = 32),\n",
    "                   epochs = 25,\n",
    "                   validation_data = (X_val, Y_val),\n",
    "                   steps_per_epoch = 10,\n",
    "                   verbose = 1\n",
    "                   )\n",
    "\n",
    "print('Validating model...')\n",
    "score, acc = model.evaluate(X_val, Y_val, verbose= 1)\n",
    "print('\\nLoss:', score, '\\nAcc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "print(\"\\nSaving model...\")\n",
    "model.save('{0:3.2f}_'.format(acc*100)+ model_name)\n",
    "print(\"\\nSaved model as {}...\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_history(history, show_acc = False)\n",
    "view_history(history, show_acc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions(model=model, \n",
    "                 test_set=X_val, \n",
    "                 val_set=Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = get_layer_names(model, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_img_in_filter(model,\n",
    "                  X_train,\n",
    "                  img_num=-2,\n",
    "                  img_res=img_res,\n",
    "                  layer_num=8,\n",
    "                  GRAY=GRAY\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sides = [11,9,9,9]\n",
    "max_pool_sides = [4,,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_convolutional(layer_num=0, filter_num=0, conv_kernel_side=kernel_sides[0], img_res=img_res, image = 0, max_prev = False, max_pooled_img=None, max_pools_per_side=img_res):\n",
    "    \n",
    "    #plt.figure(figsize = (3,3))\n",
    "\n",
    "    ## Flatten array to create continuous array\n",
    "    if max_prev == True:\n",
    "        img_res = max_pools_per_side\n",
    "    \n",
    "    \n",
    "    kernel_side = conv_kernel_side\n",
    "    kernel = kernel_side**2\n",
    "\n",
    "    neg_res = (kernel_side//2) * 2\n",
    "    new_img_res = img_res-neg_res\n",
    "    \n",
    "    \n",
    "    layer = model.layers[layer_num]\n",
    "    conv_weights = layer.get_weights()[0][:,:,0,:]\n",
    "    \n",
    "    concat_weights = np.concatenate(conv_weights[:,:,filter_num])\n",
    "    \n",
    "    convolve_flat = (kernel)*((new_img_res)**2)  ## works out size needed for flattened filter\n",
    "\n",
    "    ## Create filter array\n",
    "    filtered = np.zeros(convolve_flat)#np.zeros(img_res**2)\n",
    "\n",
    "    ## Begins loop to determine place so flat multiplication can be done\n",
    "    num = 0\n",
    "    for j in range(new_img_res):\n",
    "        for i in range(new_img_res):\n",
    "            for y in range(kernel_side):\n",
    "                for x in range(kernel_side):\n",
    "                    if max_prev == False:\n",
    "                        filtered[num] = X_imgs[image][j+y][i+x]\n",
    "                    else:\n",
    "                        filtered[num] = max_pooled_img[j+y][i+x]\n",
    "                    num += 1\n",
    "\n",
    "\n",
    "\n",
    "    filtered_im = np.zeros(convolve_flat//kernel)\n",
    "\n",
    "    for i in range(convolve_flat//kernel):\n",
    "            filtered_im[i] = np.dot(concat_weights, filtered[(i*kernel):(kernel + (i*kernel))])\n",
    "\n",
    "    filtered_im = filtered_im.reshape(new_img_res, new_img_res)\n",
    "    #filtered_im /= 255\n",
    "    #plt.imshow(filtered_im, cmap=\"gray\")\n",
    "    #plt.show()\n",
    "        \n",
    "    return filtered_im, new_img_res #new_img_res, filtered_im\n",
    "\n",
    "\n",
    "def mock_max_pooling(max_pool_side, img_res, filtered_im):\n",
    "    \n",
    "    \n",
    "    #plt.figure(figsize = (3,3))\n",
    "    max_pool = max_pool_side**2\n",
    "\n",
    "    max_pools_per_side = img_res//max_pool_side\n",
    "    max_pools_tot = max_pools_per_side**2\n",
    "\n",
    "    max_pooled_arr = np.zeros(max_pool*(img_res//max_pool_side)**2)\n",
    "    max_pooled = np.zeros(max_pools_tot)\n",
    "\n",
    "    num = 0\n",
    "    for j in range(max_pools_per_side):\n",
    "        for i in range(max_pools_per_side):\n",
    "            for y in range(max_pool_side):\n",
    "                for x in range(max_pool_side):\n",
    "                    max_pooled_arr[num] = filtered_im[(j*max_pool_side)+y][(i*max_pool_side)+x]\n",
    "                    num += 1\n",
    "\n",
    "    for pixels in range(max_pools_tot):\n",
    "        max_pooled[pixels] = max(max_pooled_arr[(max_pool*pixels):(max_pool+max_pool*pixels)])\n",
    "\n",
    "    max_pool_img = max_pooled.reshape(max_pools_per_side, max_pools_per_side)\n",
    "    #plt.imshow(max_pool_img, cmap=\"gray\")\n",
    "    #plt.show()\n",
    "\n",
    "    return max_pool_img, max_pools_per_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_num = 3\n",
    "image = 1502\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "\n",
    "filtered_im, new_img_res = mock_convolutional(layer_num=0,\n",
    "                                   filter_num=filter_num,\n",
    "                                   conv_kernel_side=kernel_sides[0],\n",
    "                                   img_res=img_res,\n",
    "                                   image=image)\n",
    "plt.subplot(1,8,1)\n",
    "plt.imshow(filtered_im,cmap=\"gray\")\n",
    "\n",
    "\n",
    "max_pool_img, max_pools_per_side = mock_max_pooling(max_pool_side=max_pool_sides[0],\n",
    "                                                     img_res=new_img_res,\n",
    "                                                     filtered_im=filtered_im)\n",
    "plt.subplot(1,8,2)\n",
    "plt.imshow(max_pool_img,cmap=\"gray\")\n",
    "\n",
    "\n",
    "filtered_im, new_img_res = mock_convolutional(layer_num=3,\n",
    "                                              filter_num=0,\n",
    "                                              conv_kernel_side=kernel_sides[1],\n",
    "                                              img_res=new_img_res,\n",
    "                                              max_prev = True,\n",
    "                                              max_pooled_img=max_pool_img,\n",
    "                                              max_pools_per_side=max_pools_per_side)\n",
    "plt.subplot(1,8,3)\n",
    "plt.imshow(filtered_im,cmap=\"gray\")\n",
    "\n",
    "\n",
    "max_pool_img, max_pools_per_side = mock_max_pooling(max_pool_side=max_pool_sides[1],\n",
    "                                                     img_res=new_img_res,\n",
    "                                                     filtered_im=filtered_im)\n",
    "plt.subplot(1,8,4)\n",
    "plt.imshow(max_pool_img,cmap=\"gray\")\n",
    "\n",
    "\n",
    "filtered_im, new_img_res = mock_convolutional(layer_num=6, \n",
    "                                              filter_num=0, \n",
    "                                              conv_kernel_side=kernel_sides[2], \n",
    "                                              img_res=new_img_res,\n",
    "                                              max_prev = True, \n",
    "                                              max_pooled_img=max_pool_img,\n",
    "                                              max_pools_per_side=max_pools_per_side)\n",
    "plt.subplot(1,8,5)\n",
    "plt.imshow(filtered_im,cmap=\"gray\")\n",
    "\n",
    "\n",
    "max_pool_img, max_pools_per_side = mock_max_pooling(max_pool_side=max_pool_sides[2],\n",
    "                                                     img_res=new_img_res,\n",
    "                                                     filtered_im=filtered_im)\n",
    "plt.subplot(1,8,6)\n",
    "plt.imshow(max_pool_img,cmap=\"gray\")\n",
    "\n",
    "\n",
    "filtered_im, new_img_res = mock_convolutional(layer_num=9, \n",
    "                                              filter_num=0, \n",
    "                                              conv_kernel_side=kernel_sides[3], \n",
    "                                              img_res=new_img_res,\n",
    "                                              image = 0, \n",
    "                                              max_prev = True, \n",
    "                                              max_pooled_img=max_pool_img,\n",
    "                                              max_pools_per_side=max_pools_per_side)\n",
    "plt.subplot(1,8,7)\n",
    "plt.imshow(filtered_im,cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
